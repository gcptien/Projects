{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "# import resnet50\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from math import sqrt\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n",
    "import glob\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory\n",
    "path = \"C:/Users/cptien/Desktop/data/pet_adoption_data/\"\n",
    "os.chdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breed_labels.csv',\n",
       " 'color_labels.csv',\n",
       " 'sample_submission.csv',\n",
       " 'state_labels.csv',\n",
       " 'test.csv',\n",
       " 'test.zip',\n",
       " 'test_images',\n",
       " 'test_images.zip',\n",
       " 'test_metadata',\n",
       " 'test_metadata.zip',\n",
       " 'test_sentiment',\n",
       " 'test_sentiment.zip',\n",
       " 'train.csv',\n",
       " 'train.zip',\n",
       " 'train_images',\n",
       " 'train_metadata',\n",
       " 'train_sentiment']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test  = pd.read_csv(\"./test.csv\")\n",
    "sample_submission = pd.read_csv(\"./sample_submission.csv\")\n",
    "breed_labels = pd.read_csv(\"./breed_labels.csv\")\n",
    "color_labels = pd.read_csv(\"./color_labels.csv\")\n",
    "state_labels = pd.read_csv(\"./state_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image, Metadata, and Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train image files: 58311\n",
      "Number of train metadata files: 58311\n",
      "Number of train sentiment files: 14442\n"
     ]
    }
   ],
   "source": [
    "train_img_files = sorted(glob.glob('./train_images/*.jpg'))\n",
    "train_mdata_files = sorted(glob.glob('./train_metadata/*.json'))\n",
    "train_senti_files = sorted(glob.glob('./train_sentiment/*.json'))\n",
    "print(f'Number of train image files: {len(train_img_files)}')\n",
    "print(f'Number of train metadata files: {len(train_mdata_files)}')\n",
    "print(f'Number of train sentiment files: {len(train_senti_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test image files: 14465\n",
      "Number of test metadata files: 14465\n",
      "Number of test sentiment files: 3865\n"
     ]
    }
   ],
   "source": [
    "test_img_files = sorted(glob.glob('./test_images/*.jpg'))\n",
    "test_mdata_files = sorted(glob.glob('./test_metadata/*.json'))\n",
    "test_senti_files = sorted(glob.glob('./test_sentiment/*.json'))\n",
    "print(f'Number of test image files: {len(test_img_files)}')\n",
    "print(f'Number of test metadata files: {len(test_mdata_files)}')\n",
    "print(f'Number of test sentiment files: {len(test_senti_files)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pets: 14993\n",
      "Pets with images: 14652\n",
      "Fraction of pets with images: 0.977\n",
      "\n",
      "Pets with Metadata: 14652\n",
      "Fraction of pets with Metadata: 0.977\n",
      "\n",
      "Pets with Sentiments: 14442\n",
      "Fraction of pets with sentiments: 0.963\n"
     ]
    }
   ],
   "source": [
    "#images\n",
    "train_ids = train[['PetID']]\n",
    "print(f'Total pets: {len(train_ids)}')\n",
    "train_imgs = pd.DataFrame(train_img_files)\n",
    "train_imgs.columns = ['image_filenames']\n",
    "train_imgs_pets = train_imgs['image_filenames'].apply(lambda x: x.split('\\\\')[-1].split('-')[0])\n",
    "train_imgs = train_imgs.assign(PetID=train_imgs_pets)\n",
    "print(f'Pets with images: {len(train_imgs_pets.unique())}')\n",
    "pets_with_images = len(np.intersect1d(train_imgs_pets.unique(), \n",
    "                                      train_ids['PetID'].unique()))\n",
    "print(f'Fraction of pets with images: {pets_with_images/train_ids.shape[0]:.3f}')\n",
    "\n",
    "#metadata\n",
    "print()\n",
    "train_mdata = pd.DataFrame(train_mdata_files, columns=['metadata_filenames'])\n",
    "train_mdata_pets = train_mdata['metadata_filenames'].apply(lambda x:x.split('\\\\')[-1].split('-')[0])\n",
    "train_mdata['PetID'] = train_mdata_pets\n",
    "print(f'Pets with Metadata: {len(train_mdata_pets.unique())}')\n",
    "pets_with_metadata = len(np.intersect1d(train_mdata_pets.unique(), train_ids['PetID'].unique()))\n",
    "print(f'Fraction of pets with Metadata: {pets_with_metadata/train_ids.shape[0]:.3}')\n",
    "print()\n",
    "\n",
    "#sentiments\n",
    "train_senti = pd.DataFrame(train_senti_files, columns=['sentiment_filenames'])\n",
    "train_senti_pets = train_senti['sentiment_filenames'].apply(lambda x: x.split('\\\\')[-1].split('.')[0])\n",
    "train_senti['PetID'] = train_senti_pets\n",
    "print(f'Pets with Sentiments: {len(train_senti_pets.unique())}')\n",
    "\n",
    "pets_with_senti = len(np.intersect1d(train_senti_pets.unique(), train_ids['PetID'].unique()))\n",
    "print(f'Fraction of pets with sentiments: {pets_with_senti/train_ids.shape[0]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pets: 3972\n",
      "Pets with images: 3858\n",
      "Fraction of pets with images: 0.971\n",
      "\n",
      "Pets with Metadata: 3858\n",
      "Fraction of pets with Metadata: 0.971\n",
      "\n",
      "Pets with Sentiments: 3865\n",
      "Fraction of pets with sentiments: 0.973\n",
      "\n",
      "Images and Metadata distribution are the same? True\n"
     ]
    }
   ],
   "source": [
    "#images\n",
    "test_ids = test[['PetID']]\n",
    "print(f'Total pets: {len(test_ids)}')\n",
    "test_imgs = pd.DataFrame(test_img_files,columns=['image_filenames'])\n",
    "\n",
    "test_imgs_pets = test_imgs['image_filenames'].apply(lambda x: x.split('\\\\')[-1].split('-')[0])\n",
    "test_imgs = test_imgs.assign(PetID=test_imgs_pets)\n",
    "print(f'Pets with images: {len(test_imgs_pets.unique())}')\n",
    "pets_with_images = len(np.intersect1d(test_imgs_pets.unique(), \n",
    "                                      test_ids['PetID'].unique()))\n",
    "print(f'Fraction of pets with images: {pets_with_images/test_ids.shape[0]:.3f}')\n",
    "\n",
    "#metadata\n",
    "print()\n",
    "test_mdata = pd.DataFrame(test_mdata_files, columns=['metadata_filenames'])\n",
    "test_mdata_pets = test_mdata['metadata_filenames'].apply(lambda x:x.split('\\\\')[-1].split('-')[0])\n",
    "test_mdata['PetID'] = test_mdata_pets\n",
    "print(f'Pets with Metadata: {len(test_mdata_pets.unique())}')\n",
    "pets_with_metadata = len(np.intersect1d(test_mdata_pets.unique(), test_ids['PetID'].unique()))\n",
    "print(f'Fraction of pets with Metadata: {pets_with_metadata/test_ids.shape[0]:.3}')\n",
    "print()\n",
    "\n",
    "#sentiments\n",
    "test_senti = pd.DataFrame(test_senti_files, columns=['sentiment_filenames'])\n",
    "test_senti_pets = test_senti['sentiment_filenames'].apply(lambda x: x.split('\\\\')[-1].split('.')[0])\n",
    "test_senti['PetID'] = test_senti_pets\n",
    "print(f'Pets with Sentiments: {len(test_senti_pets.unique())}')\n",
    "\n",
    "pets_with_senti = len(np.intersect1d(test_senti_pets.unique(), test_ids['PetID'].unique()))\n",
    "print(f'Fraction of pets with sentiments: {pets_with_senti/test_ids.shape[0]:.3}')\n",
    "print()\n",
    "print(f'Images and Metadata distribution are the same? {np.all(test_mdata_pets==test_imgs_pets)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetFinderParser(object):\n",
    "    def __init__(self, debug=False):\n",
    "        self.debug = debug\n",
    "        self.sentence_sep = ' '\n",
    "        self.extract_sentiment_text = False\n",
    "    \n",
    "    def open_metadata_file(self, filename):\n",
    "        # Load metadata file\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            metadata_file = json.load(f)\n",
    "        return metadata_file\n",
    "    \n",
    "    def open_sentiment_file(self, filename):\n",
    "        # Load sentiment file\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            sentiment_file = json.load(f)\n",
    "        return sentiment_file\n",
    "    \n",
    "    def open_image_file(self, filename):\n",
    "        # Load image file\n",
    "        with open(filename, 'r') as f:\n",
    "            image_file = json.load(f)\n",
    "        return image_file\n",
    "\n",
    "    def parse_sentiment_file(self, file):\n",
    "        # Parse sentiment file.\n",
    "        file_sentiment = file['documentSentiment']\n",
    "        file_entities = [x['name'] for x in file['entities']]\n",
    "        file_entities = self.sentence_sep.join(file_entities)\n",
    "        \n",
    "        if self.extract_sentiment_text:\n",
    "            file_sentence_text = [x['text']['content'] for x in file['sentences']]\n",
    "            file_sentence_text = self.sentence_sep.join(file_sentence_text)\n",
    "            \n",
    "        file_sentence_sentiment = [x['sentiment'] for x in file['sentences']]\n",
    "        file_sentence_sentiment = pd.DataFrame.from_dict(file_sentence_sentiment, orient='columns').sum()\n",
    "        file_sentence_sentiment = file_sentence_sentiment.add_prefix('document_').to_dict()\n",
    "        \n",
    "        file_sentiment.update(file_sentence_sentiment)\n",
    "        \n",
    "        df_sentiment = pd.DataFrame.from_dict(file_sentiment, orient='index').T\n",
    "        if self.extract_sentiment_text:\n",
    "            df_sentiment['text'] = file_sentence_text\n",
    "        \n",
    "        df_sentiment['entities'] = file_entities\n",
    "        df_sentiment = df_sentiment.add_prefix('sentiment_')\n",
    "        \n",
    "        return df_sentiment\n",
    "    \n",
    "    def parse_metadata_file(self, file):\n",
    "        # Parsse metadta file\n",
    "        \n",
    "        file_keys=list(file.keys())\n",
    "        \n",
    "        if 'labelAnnotations' in file_keys:\n",
    "            file_annots = file['labelAnnotations'][:int(len(file['labelAnnotations']) * 0.3)]\n",
    "            file_top_score = np.asarray([x['score'] for x in file_annots]).mean()\n",
    "            file_top_desc = [x['description'] for x in file_annots]\n",
    "        else:\n",
    "            file_top_score = np.nan\n",
    "            file_top_desc = ['']\n",
    "            \n",
    "        file_colors = file['imagePropertiesAnnotation']['dominantColors']['colors']\n",
    "        file_crops = file['cropHintsAnnotation']['cropHints']\n",
    "        \n",
    "        file_color_score = np.asarray([x['score'] for x in file_colors]).mean()\n",
    "        file_color_pixelfrac = np.asarray([x['pixelFraction'] for x in file_colors]).mean()\n",
    "        \n",
    "        file_crop_conf = np.asarray([x['confidence'] for x in file_crops]).mean()\n",
    "        \n",
    "        if 'importanceFraction'  in file_crops[0].keys():\n",
    "            file_crop_importance = np.asarray([x['importanceFraction'] for x in file_crops]).mean()\n",
    "        \n",
    "        else:\n",
    "            file_crop_importance = np.nan\n",
    "            \n",
    "        df_metadata = {\n",
    "            'annots_score': file_top_score,\n",
    "            'color_score': file_color_score,\n",
    "            'color_pixelfrac': file_color_pixelfrac,\n",
    "            'crop_conf': file_crop_conf,\n",
    "            'crop_importance': file_crop_importance,\n",
    "            'annots_top_desc': self.sentence_sep.join(file_top_desc)\n",
    "        }\n",
    "            \n",
    "        df_metadata = pd.DataFrame.from_dict(df_metadata, orient='index').T\n",
    "        df_metadata = df_metadata.add_prefix('metadata_')\n",
    "        \n",
    "        return df_metadata\n",
    "    \n",
    "# Helper fuction for parallel data processing:\n",
    "def extract_additional_features(pet_id, mode='train'):\n",
    "    sentiment_filename = f'./{mode}_sentiment/{pet_id}.json'\n",
    "    \n",
    "    try:\n",
    "        sentiment_file = pet_parser.open_sentiment_file(sentiment_filename)\n",
    "        df_sentiment = pet_parser.parse_sentiment_file(sentiment_file)\n",
    "        df_sentiment['PetID'] = pet_id\n",
    "    except FileNotFoundError:\n",
    "        df_sentiment = []\n",
    "    \n",
    "    dfs_metadata = []\n",
    "    metadata_filenames = sorted(glob.glob(f'./{mode}_metadata/{pet_id}*.json'))\n",
    "    if len(metadata_filenames) > 0:\n",
    "        for f in metadata_filenames:\n",
    "            metadata_file = pet_parser.open_metadata_file(f)\n",
    "            df_metadata = pet_parser.parse_metadata_file(metadata_file)\n",
    "            df_metadata['PetID'] = pet_id\n",
    "            dfs_metadata.append(df_metadata)\n",
    "        dfs_metadata = pd.concat(dfs_metadata, ignore_index=True, sort=False)\n",
    "    dfs= [df_sentiment, dfs_metadata]\n",
    "        \n",
    "    return dfs\n",
    "            \n",
    "            \n",
    "pet_parser = PetFinderParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique IDs from train and test:\n",
    "debug = False\n",
    "train_pet_ids = train['PetID'].unique()\n",
    "test_pet_ids = test['PetID'].unique()\n",
    "\n",
    "if debug:\n",
    "    train_pet_ids = train_pet_ids[:1000]\n",
    "    test_pet_ids = test_pet_ids[:500]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=6)]: Done 2438 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=6)]: Done 3188 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=6)]: Done 4038 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=6)]: Done 4988 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=6)]: Done 6038 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=6)]: Done 7188 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=6)]: Done 8438 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=6)]: Done 9788 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=6)]: Done 11238 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=6)]: Done 12788 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=6)]: Done 14438 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=6)]: Done 14993 out of 14993 | elapsed: 32.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Train Set:\n",
    "# Parallel processsing of data:\n",
    "dfs_train = Parallel(n_jobs=6, verbose=1)(delayed(extract_additional_features)(i,mode='train') for i in train_pet_ids)\n",
    "# dfs_train = [extract_additional_features(i, mode='train') for i in train_pet_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-8341c9f40a1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfs_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14442, 6) (58311, 7)\n"
     ]
    }
   ],
   "source": [
    "# Train Set\n",
    "train_dfs_sentiment = [x[0] for x in dfs_train if isinstance(x[0], pd.DataFrame)]\n",
    "train_dfs_metadata = [x[1] for x in dfs_train if isinstance(x[1], pd.DataFrame)]\n",
    "\n",
    "train_dfs_sentiment  = pd.concat(train_dfs_sentiment, ignore_index=True, sort=False)\n",
    "train_dfs_metadata = pd.concat(train_dfs_metadata, ignore_index=True, sort=False)\n",
    "print(train_dfs_sentiment.shape, train_dfs_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 2438 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=6)]: Done 3188 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=6)]: Done 3972 out of 3972 | elapsed:  3.4min finished\n"
     ]
    }
   ],
   "source": [
    "# Test Set\n",
    "dfs_test = Parallel(n_jobs=6, verbose=1)(delayed(extract_additional_features)(i, mode='test') for i in test_pet_ids)\n",
    "\n",
    "test_dfs_sentiment = [x[0] for x in dfs_test if isinstance(x[0], pd.DataFrame)]\n",
    "test_dfs_metadata = [x[1] for x in dfs_test if isinstance(x[1], pd.DataFrame)]\n",
    "\n",
    "test_dfs_sentiment = pd.concat(test_dfs_sentiment, ignore_index=True, sort=False)\n",
    "test_dfs_metadata = pd.concat(test_dfs_metadata, ignore_index=True, sort=False)\n",
    "print(test_dfs_sentiment.shape, test_dfs_metadata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata_annots_score</th>\n",
       "      <th>metadata_color_score</th>\n",
       "      <th>metadata_color_pixelfrac</th>\n",
       "      <th>metadata_crop_conf</th>\n",
       "      <th>metadata_crop_importance</th>\n",
       "      <th>metadata_annots_top_desc</th>\n",
       "      <th>PetID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973658</td>\n",
       "      <td>0.0748377</td>\n",
       "      <td>0.066331</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>cat black cat</td>\n",
       "      <td>86e1089a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.926158</td>\n",
       "      <td>0.0873303</td>\n",
       "      <td>0.0681004</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>cat whiskers small to medium sized cats</td>\n",
       "      <td>6296e909a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.951545</td>\n",
       "      <td>0.0960851</td>\n",
       "      <td>0.0592612</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>cat small to medium sized cats</td>\n",
       "      <td>6296e909a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.947711</td>\n",
       "      <td>0.0985924</td>\n",
       "      <td>0.0407908</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>dog dog like mammal dog breed</td>\n",
       "      <td>3422e4906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.95744</td>\n",
       "      <td>0.0983332</td>\n",
       "      <td>0.0969476</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>dog dog like mammal dog breed</td>\n",
       "      <td>3422e4906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metadata_annots_score metadata_color_score metadata_color_pixelfrac  \\\n",
       "0              0.973658            0.0748377                 0.066331   \n",
       "1              0.926158            0.0873303                0.0681004   \n",
       "2              0.951545            0.0960851                0.0592612   \n",
       "3              0.947711            0.0985924                0.0407908   \n",
       "4               0.95744            0.0983332                0.0969476   \n",
       "\n",
       "  metadata_crop_conf metadata_crop_importance  \\\n",
       "0                0.8                        1   \n",
       "1                0.8                        1   \n",
       "2                0.8                        1   \n",
       "3                0.8                        1   \n",
       "4                0.8                        1   \n",
       "\n",
       "                  metadata_annots_top_desc      PetID  \n",
       "0                            cat black cat  86e1089a3  \n",
       "1  cat whiskers small to medium sized cats  6296e909a  \n",
       "2           cat small to medium sized cats  6296e909a  \n",
       "3            dog dog like mammal dog breed  3422e4906  \n",
       "4            dog dog like mammal dog breed  3422e4906  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dfs_metadata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend aggregates and imporve column naming\n",
    "aggregates =['mean', 'sum']\n",
    "\n",
    "#Train\n",
    "train_metadata_desc = train_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n",
    "train_metadata_desc = train_metadata_desc.reset_index()\n",
    "train_metadata_desc['metadata_annots_top_desc'] = train_metadata_desc['metadata_annots_top_desc'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "prefix = 'metadata'\n",
    "train_metadata_gr = train_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n",
    "for i in train_metadata_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        train_metadata_gr[i] = train_metadata_gr[i].astype(float)\n",
    "\n",
    "train_metadata_gr = train_metadata_gr.groupby(['PetID']).agg(aggregates)\n",
    "train_metadata_gr.columns = pd.Index([f'{prefix}_{c[0]}_{c[1].upper()}' for c in train_metadata_gr.columns.tolist()])\n",
    "train_metadata_gr = train_metadata_gr.reset_index()\n",
    "\n",
    "train_sentiment_desc = train_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n",
    "train_sentiment_desc = train_sentiment_desc.reset_index()\n",
    "train_sentiment_desc['sentiment_entities']= train_sentiment_desc['sentiment_entities'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "prefix = 'sentiment'\n",
    "train_sentiment_gr = train_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n",
    "for i in train_sentiment_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        train_sentiment_gr[i] = train_sentiment_gr[i].astype(float)\n",
    "\n",
    "train_sentiment_gr = train_sentiment_gr.groupby(['PetID']).agg(aggregates)\n",
    "train_sentiment_gr.columns = pd.Index([f'{prefix}_{c[0]}_{c[1].upper()}' for c in train_sentiment_gr.columns.tolist()])\n",
    "train_sentiment_gr = train_sentiment_gr.reset_index()\n",
    "\n",
    "# Test\n",
    "\n",
    "test_metadata_desc = test_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n",
    "test_metadata_desc = test_metadata_desc.reset_index()\n",
    "test_metadata_desc['metadata_annots_top_desc'] = test_metadata_desc['metadata_annots_top_desc'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "prefix = 'metadata'\n",
    "test_metadata_gr = test_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n",
    "for i in test_metadata_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        test_metadata_gr[i] = test_metadata_gr[i].astype(float)\n",
    "\n",
    "test_metadata_gr = test_metadata_gr.groupby(['PetID']).agg(aggregates)\n",
    "test_metadata_gr.columns = pd.Index([f'{prefix}_{c[0]}_{c[1].upper()}' for c in test_metadata_gr.columns.tolist()])\n",
    "test_metadata_gr = test_metadata_gr.reset_index()\n",
    "\n",
    "test_sentiment_desc = test_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n",
    "test_sentiment_desc = test_sentiment_desc.reset_index()\n",
    "test_sentiment_desc['sentiment_entities']= test_sentiment_desc['sentiment_entities'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "prefix = 'sentiment'\n",
    "test_sentiment_gr = test_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n",
    "for i in test_sentiment_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        test_sentiment_gr[i] = test_sentiment_gr[i].astype(float)\n",
    "\n",
    "test_sentiment_gr = test_sentiment_gr.groupby(['PetID']).agg(aggregates)\n",
    "test_sentiment_gr.columns = pd.Index([f'{prefix}_{c[0]}_{c[1].upper()}' for c in test_sentiment_gr.columns.tolist()])\n",
    "test_sentiment_gr = test_sentiment_gr.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 44) (3972, 43)\n"
     ]
    }
   ],
   "source": [
    "# Train Merges:\n",
    "train_proc = train.copy()\n",
    "train_proc = train_proc.merge(train_sentiment_gr, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(train_metadata_gr, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(train_sentiment_desc, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(train_metadata_desc, how='left', on='PetID')\n",
    "\n",
    "# Test Merges:\n",
    "test_proc = test.copy()\n",
    "test_proc = test_proc.merge(test_sentiment_gr, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(test_metadata_gr, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(test_sentiment_desc, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(test_metadata_desc, how='left', on='PetID')\n",
    "\n",
    "print(train_proc.shape, test_proc.shape)\n",
    "assert train_proc.shape[0] == train.shape[0]\n",
    "assert test_proc.shape[0] == test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breed Mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 60) (3972, 55)\n"
     ]
    }
   ],
   "source": [
    "train_breed_main = train_proc[['Breed1']].merge(\n",
    "                    breed_labels, how='left', left_on='Breed1',\n",
    "                    right_on='BreedID', suffixes=('', '_main_breed'))\n",
    "\n",
    "train_breed_main = train_breed_main.iloc[:,2:]\n",
    "train_breed_main = train_breed_main.add_prefix('main_breed_')\n",
    "\n",
    "train_breed_second = train_proc[['Breed2']].merge(\n",
    "                    breed_labels, how='left', left_on='Breed2',\n",
    "                    right_on='BreedID', suffixes=('', '_second_breed'))\n",
    "\n",
    "train_breed_second = train_breed_second.iloc[:,2:]\n",
    "train_breed_second = train_breed_second.add_prefix('second_breed_')\n",
    "\n",
    "train_proc = pd.concat([train_proc, train_breed_main,train_breed_second], axis=1)\n",
    "\n",
    "test_breed_main = test_proc[['Breed1']].merge(\n",
    "                    breed_labels, how='left',\n",
    "                    left_on='Breed1', right_on='BreedID',\n",
    "                    suffixes=('','_main_breed')\n",
    "                    )\n",
    "\n",
    "test_breed_main = test_breed_main.iloc[:,2:]\n",
    "test_breed_main = test_breed_main.add_prefix('main_breed_')\n",
    "\n",
    "test_breed_second = test_proc[['Breed2']].merge(\n",
    "                    breed_labels, how='left', left_on='Breed2',\n",
    "                    right_on='BreedID', suffixes=('', '_second_breed'))\n",
    "\n",
    "test_breed_second = test_breed_second.iloc[:,2:]\n",
    "test_breed_second = test_breed_second.add_prefix('second_breed_')\n",
    "\n",
    "test_proc = pd.concat([test_proc, test_breed_main,test_breed_second], axis=1)\n",
    "\n",
    "print(train_proc.shape, test_proc.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Train and test\n",
    "### Inspect NaN srtructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Plan shapes are not aligned",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-376e561a2c68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_proc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_proc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'NaN Structure: \\n{np.sum(pd.isnull(X))}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                        copy=copy, sort=sort)\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    424\u001b[0m             new_data = concatenate_block_managers(\n\u001b[0;32m    425\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m                 copy=self.copy)\n\u001b[0m\u001b[0;32m    427\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   2044\u001b[0m     \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2046\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin_units\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconcat_plan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mcombine_concat_plans\u001b[1;34m(plans, concat_axis)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mnum_ended\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnum_ended\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Plan shapes are not aligned\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[0mplacements\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnext_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Plan shapes are not aligned"
     ]
    }
   ],
   "source": [
    "X = pd.concat([train_proc, test_proc], ignore_index=True, sort=False)\n",
    "print(f'NaN Structure: \\n{np.sum(pd.isnull(X))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-ad782a75d027>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcolumn_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mint_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_types\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_types\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'int'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfloat_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_types\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_types\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcat_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_types\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_types\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'object'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "column_types = X.dtypes\n",
    "int_cols = column_types[column_types == 'int']\n",
    "float_cols = column_types[column_types =='float']\n",
    "cat_cols = column_types[column_types == 'object']\n",
    "\n",
    "print(f'\\tInteger Columns:\\n{int_cols}')\n",
    "print(f'\\n\\tFloat Columns:\\n{float_cols}')\n",
    "print(f'\\n\\Categorical Columns:\\n{cat_cols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-164-3d6d66ef8039>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtext_columns\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Description'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'metadata_annots_top_desc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sentiment_entities'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcategorical_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'main_breed_BreedName'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sencond_breed_BreedName'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_temp = X.copy()\n",
    "\n",
    "text_columns= ['Description','metadata_annots_top_desc','sentiment_entities']\n",
    "categorical_columns=['main_breed_BreedName','sencond_breed_BreedName']\n",
    "\n",
    "to_drop_columns=['PetID', 'Name','RescuerID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-165-bd8b412c8287>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrescuer_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RescuerID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PetID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrescuer_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'RescuerID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Rescuer_count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Merger rescuer count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrescuer_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'RescueID'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "rescuer_count = X.groupby(['RescuerID'])['PetID'].count().reset_index()\n",
    "rescuer_count.columns = ['RescuerID','Rescuer_count']\n",
    "\n",
    "# Merger rescuer count\n",
    "X_temp = X_temp.merge(rescuer_count, how='left', on='RescueID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categorical_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-166-4369febb4895>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Factorize categorical columns:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcategorical_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mX_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'categorical_columns' is not defined"
     ]
    }
   ],
   "source": [
    "# Factorize categorical columns:\n",
    "for i in categorical_columns:\n",
    "    X_temp.loc[:,i] = pd.factorize(X_temp.loc[:,i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-168-0d0900977399>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mX_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<MISSING>'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_temp' is not defined"
     ]
    }
   ],
   "source": [
    "X_text = X_temp[text_columns]\n",
    "\n",
    "for i in X_text.columns:\n",
    "    X_text.loc[:,i] = X_text.loc[:,i].fillna('<MISSING>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
