{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "# import resnet50\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from math import sqrt\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n",
    "import glob\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory\n",
    "path = \"C:/Users/cptien/Desktop/data/pet_adoption_data/\"\n",
    "os.chdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breed_labels.csv',\n",
       " 'color_labels.csv',\n",
       " 'sample_submission.csv',\n",
       " 'state_labels.csv',\n",
       " 'test.csv',\n",
       " 'test.zip',\n",
       " 'test_images',\n",
       " 'test_images.zip',\n",
       " 'test_metadata',\n",
       " 'test_metadata.zip',\n",
       " 'test_sentiment',\n",
       " 'test_sentiment.zip',\n",
       " 'train.csv',\n",
       " 'train.zip',\n",
       " 'train_images',\n",
       " 'train_metadata',\n",
       " 'train_sentiment']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test  = pd.read_csv(\"./test.csv\")\n",
    "sample_submission = pd.read_csv(\"./sample_submission.csv\")\n",
    "breed_labels = pd.read_csv(\"./breed_labels.csv\")\n",
    "color_labels = pd.read_csv(\"./color_labels.csv\")\n",
    "state_labels = pd.read_csv(\"./state_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image, Metadata, and Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train image files: 58311\n",
      "Number of train metadata files: 58311\n",
      "Number of train sentiment files: 14442\n"
     ]
    }
   ],
   "source": [
    "train_img_files = sorted(glob.glob('./train_images/*.jpg'))\n",
    "train_mdata_files = sorted(glob.glob('./train_metadata/*.json'))\n",
    "train_senti_files = sorted(glob.glob('./train_sentiment/*.json'))\n",
    "print(f'Number of train image files: {len(train_img_files)}')\n",
    "print(f'Number of train metadata files: {len(train_mdata_files)}')\n",
    "print(f'Number of train sentiment files: {len(train_senti_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test image files: 14465\n",
      "Number of test metadata files: 14465\n",
      "Number of test sentiment files: 3865\n"
     ]
    }
   ],
   "source": [
    "test_img_files = sorted(glob.glob('./test_images/*.jpg'))\n",
    "test_mdata_files = sorted(glob.glob('./test_metadata/*.json'))\n",
    "test_senti_files = sorted(glob.glob('./test_sentiment/*.json'))\n",
    "print(f'Number of test image files: {len(test_img_files)}')\n",
    "print(f'Number of test metadata files: {len(test_mdata_files)}')\n",
    "print(f'Number of test sentiment files: {len(test_senti_files)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pets: 14993\n",
      "Pets with images: 14652\n",
      "Fraction of pets with images: 0.977\n",
      "\n",
      "Pets with Metadata: 14652\n",
      "Fraction of pets with Metadata: 0.977\n",
      "\n",
      "Pets with Sentiments: 14442\n",
      "Fraction of pets with sentiments: 0.963\n"
     ]
    }
   ],
   "source": [
    "#images\n",
    "train_ids = train[['PetID']]\n",
    "print(f'Total pets: {len(train_ids)}')\n",
    "train_imgs = pd.DataFrame(train_img_files)\n",
    "train_imgs.columns = ['image_filenames']\n",
    "train_imgs_pets = train_imgs['image_filenames'].apply(lambda x: x.split('\\\\')[-1].split('-')[0])\n",
    "train_imgs = train_imgs.assign(PetID=train_imgs_pets)\n",
    "print(f'Pets with images: {len(train_imgs_pets.unique())}')\n",
    "pets_with_images = len(np.intersect1d(train_imgs_pets.unique(), \n",
    "                                      train_ids['PetID'].unique()))\n",
    "print(f'Fraction of pets with images: {pets_with_images/train_ids.shape[0]:.3f}')\n",
    "\n",
    "#metadata\n",
    "print()\n",
    "train_mdata = pd.DataFrame(train_mdata_files, columns=['metadata_filenames'])\n",
    "train_mdata_pets = train_mdata['metadata_filenames'].apply(lambda x:x.split('\\\\')[-1].split('-')[0])\n",
    "train_mdata['PetID'] = train_mdata_pets\n",
    "print(f'Pets with Metadata: {len(train_mdata_pets.unique())}')\n",
    "pets_with_metadata = len(np.intersect1d(train_mdata_pets.unique(), train_ids['PetID'].unique()))\n",
    "print(f'Fraction of pets with Metadata: {pets_with_metadata/train_ids.shape[0]:.3}')\n",
    "print()\n",
    "\n",
    "#sentiments\n",
    "train_senti = pd.DataFrame(train_senti_files, columns=['sentiment_filenames'])\n",
    "train_senti_pets = train_senti['sentiment_filenames'].apply(lambda x: x.split('\\\\')[-1].split('.')[0])\n",
    "train_senti['PetID'] = train_senti_pets\n",
    "print(f'Pets with Sentiments: {len(train_senti_pets.unique())}')\n",
    "\n",
    "pets_with_senti = len(np.intersect1d(train_senti_pets.unique(), train_ids['PetID'].unique()))\n",
    "print(f'Fraction of pets with sentiments: {pets_with_senti/train_ids.shape[0]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pets: 3972\n",
      "Pets with images: 3858\n",
      "Fraction of pets with images: 0.971\n",
      "\n",
      "Pets with Metadata: 3858\n",
      "Fraction of pets with Metadata: 0.971\n",
      "\n",
      "Pets with Sentiments: 3865\n",
      "Fraction of pets with sentiments: 0.973\n",
      "\n",
      "Images and Metadata distribution are the same? True\n"
     ]
    }
   ],
   "source": [
    "#images\n",
    "test_ids = test[['PetID']]\n",
    "print(f'Total pets: {len(test_ids)}')\n",
    "test_imgs = pd.DataFrame(test_img_files,columns=['image_filenames'])\n",
    "\n",
    "test_imgs_pets = test_imgs['image_filenames'].apply(lambda x: x.split('\\\\')[-1].split('-')[0])\n",
    "test_imgs = test_imgs.assign(PetID=test_imgs_pets)\n",
    "print(f'Pets with images: {len(test_imgs_pets.unique())}')\n",
    "pets_with_images = len(np.intersect1d(test_imgs_pets.unique(), \n",
    "                                      test_ids['PetID'].unique()))\n",
    "print(f'Fraction of pets with images: {pets_with_images/test_ids.shape[0]:.3f}')\n",
    "\n",
    "#metadata\n",
    "print()\n",
    "test_mdata = pd.DataFrame(test_mdata_files, columns=['metadata_filenames'])\n",
    "test_mdata_pets = test_mdata['metadata_filenames'].apply(lambda x:x.split('\\\\')[-1].split('-')[0])\n",
    "test_mdata['PetID'] = test_mdata_pets\n",
    "print(f'Pets with Metadata: {len(test_mdata_pets.unique())}')\n",
    "pets_with_metadata = len(np.intersect1d(test_mdata_pets.unique(), test_ids['PetID'].unique()))\n",
    "print(f'Fraction of pets with Metadata: {pets_with_metadata/test_ids.shape[0]:.3}')\n",
    "print()\n",
    "\n",
    "#sentiments\n",
    "test_senti = pd.DataFrame(test_senti_files, columns=['sentiment_filenames'])\n",
    "test_senti_pets = test_senti['sentiment_filenames'].apply(lambda x: x.split('\\\\')[-1].split('.')[0])\n",
    "test_senti['PetID'] = test_senti_pets\n",
    "print(f'Pets with Sentiments: {len(test_senti_pets.unique())}')\n",
    "\n",
    "pets_with_senti = len(np.intersect1d(test_senti_pets.unique(), test_ids['PetID'].unique()))\n",
    "print(f'Fraction of pets with sentiments: {pets_with_senti/test_ids.shape[0]:.3}')\n",
    "print()\n",
    "print(f'Images and Metadata distribution are the same? {np.all(test_mdata_pets==test_imgs_pets)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetFinderParser(object):\n",
    "    def __init__(self, debug=False):\n",
    "        self.debug = debug\n",
    "        self.sentence_sep = ' '\n",
    "        self.extract_sentiment_text = False\n",
    "    \n",
    "    def open_metadata_file(self, filename):\n",
    "        # Load metadata file\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            metadata_file = json.load(f)\n",
    "        return metadata_file\n",
    "    \n",
    "    def open_sentiment_file(self, filename):\n",
    "        # Load sentiment file\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            sentiment_file = json.load(f)\n",
    "        return sentiment_file\n",
    "    \n",
    "    def open_image_file(self, filename):\n",
    "        # Load image file\n",
    "        with open(filename, 'r') as f:\n",
    "            image_file = json.load(f)\n",
    "        return image_file\n",
    "\n",
    "    def parse_sentiment_file(self, file):\n",
    "        # Parse sentiment file.\n",
    "        file_sentiment = file['documentSentiment']\n",
    "        file_entities = [x['name'] for x in file['entities']]\n",
    "        file_entities = self.sentence_sep.join(file_entities)\n",
    "        \n",
    "        if self.extract_sentiment_text:\n",
    "            file_sentence_text = [x['text']['content'] for x in file['sentences']]\n",
    "            file_sentence_text = self.sentence_sep.join(file_sentence_text)\n",
    "            \n",
    "        file_sentence_sentiment = [x['sentiment'] for x in file['sentences']]\n",
    "        file_sentence_sentiment = pd.DataFrame.from_dict(file_sentence_sentiment, orient='columns').sum()\n",
    "        file_sentence_sentiment = file_sentence_sentiment.add_prefix('document_').to_dict()\n",
    "        \n",
    "        file_sentiment.update(file_sentence_sentiment)\n",
    "        \n",
    "        df_sentiment = pd.DataFrame.from_dict(file_sentiment, orient='index').T\n",
    "        if self.extract_sentiment_text:\n",
    "            df_sentiment['text'] = file_sentence_text\n",
    "        \n",
    "        df_sentiment['entities'] = file_entities\n",
    "        df_sentiment = df_sentiment.add_prefix('sentiment_')\n",
    "        \n",
    "        return df_sentiment\n",
    "    \n",
    "    def parse_metadata_file(self, file):\n",
    "        # Parsse metadta file\n",
    "        \n",
    "        file_keys=list(file.keys())\n",
    "        \n",
    "        if 'labelAnnotations' in file_keys:\n",
    "            file_annots = file['labelAnnotations'][:int(len(file['labelAnnotations']) * 0.3)]\n",
    "            file_top_score = np.asarray([x['score'] for x in file_annots]).mean()\n",
    "            file_top_desc = [x['description'] for x in file_annots]\n",
    "        else:\n",
    "            file_top_score = np.nan\n",
    "            file_top_desc = ['']\n",
    "            \n",
    "        file_colors = file['imagePropertiesAnnotation']['dominantColors']['colors']\n",
    "        file_crops = file['cropHintsAnnotation']['cropHints']\n",
    "        \n",
    "        file_color_score = np.asarray([x['score'] for x in file_colors]).mean()\n",
    "        file_color_pixelfrac = np.asarray([x['pixelFraction'] for x in file_colors]).mean()\n",
    "        \n",
    "        file_crop_conf = np.asarray([x['confidence'] for x in file_crops]).mean()\n",
    "        \n",
    "        if 'importanceFraction'  in file_crops[0].keys():\n",
    "            file_crop_importance = np.asarray([x['importanceFraction'] for x in file_crops]).mean()\n",
    "        \n",
    "        else:\n",
    "            file_crop_importance = np.nan\n",
    "            \n",
    "        df_metadata = {\n",
    "            'annots_score': file_top_score,\n",
    "            'color_score': file_color_score,\n",
    "            'color_pixelfrac': file_color_pixelfrac,\n",
    "            'crop_conf': file_crop_conf,\n",
    "            'crop_importance': file_crop_importance,\n",
    "            'annots_top_desc': self.sentence_sep.join(file_top_desc)\n",
    "        }\n",
    "            \n",
    "        df_metadata = pd.DataFrame.from_dict(df_metadata, orient='index').T\n",
    "        df_metadata = df_metadata.add_prefix('metadata_')\n",
    "        \n",
    "        return df_metadata\n",
    "    \n",
    "# Helper fuction for parallel data processing:\n",
    "def extract_additional_features(pet_id, mode='train'):\n",
    "    sentiment_filename = f'./{mode}_sentiment/{pet_id}.json'\n",
    "    \n",
    "    try:\n",
    "        sentiment_file = pet_parser.open_sentiment_file(sentiment_filename)\n",
    "        df_sentiment = pet_parser.parse_sentiment_file(sentiment_file)\n",
    "        df_sentiment['PetID'] = pet_id\n",
    "    except FileNotFoundError:\n",
    "        df_sentiment = []\n",
    "    \n",
    "    dfs_metadata = []\n",
    "    metadata_filenames = sorted(glob.glob(f'./{mode}_metadata/{pet_id}*.json'))\n",
    "    if len(metadata_filenames) > 0:\n",
    "        for f in metadata_filenames:\n",
    "            metadata_file = pet_parser.open_metadata_file(f)\n",
    "            df_metadata = pet_parser.parse_metadata_file(metadata_file)\n",
    "            df_metadata['PetID'] = pet_id\n",
    "            dfs_metadata.append(df_metadata)\n",
    "        dfs_metadata = pd.concat(dfs_metadata, ignore_index=True, sort=False)\n",
    "    dfs= [df_sentiment, dfs_metadata]\n",
    "        \n",
    "    return dfs\n",
    "            \n",
    "            \n",
    "pet_parser = PetFinderParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique IDs from train and test:\n",
    "debug = False\n",
    "train_pet_ids = train['PetID'].unique()\n",
    "test_pet_ids = test['PetID'].unique()\n",
    "\n",
    "if debug:\n",
    "    train_pet_ids = train_pet_ids[:1000]\n",
    "    test_pet_ids = test_pet_ids[:500]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=6)]: Done 2438 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=6)]: Done 3188 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=6)]: Done 4038 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=6)]: Done 4988 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=6)]: Done 6038 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=6)]: Done 7188 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=6)]: Done 8438 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=6)]: Done 9788 tasks      | elapsed: 22.4min\n",
      "[Parallel(n_jobs=6)]: Done 11238 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=6)]: Done 12788 tasks      | elapsed: 29.8min\n",
      "[Parallel(n_jobs=6)]: Done 14438 tasks      | elapsed: 33.8min\n",
      "[Parallel(n_jobs=6)]: Done 14993 out of 14993 | elapsed: 35.2min finished\n"
     ]
    }
   ],
   "source": [
    "# Train Set:\n",
    "# Parallel processsing of data:\n",
    "dfs_train = Parallel(n_jobs=6, verbose=1)(delayed(extract_additional_features)(i,mode='train') for i in train_pet_ids)\n",
    "# dfs_train = [extract_additional_features(i, mode='train') for i in train_pet_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14442, 6) (58311, 7)\n"
     ]
    }
   ],
   "source": [
    "# Train Set\n",
    "train_dfs_sentiment = [x[0] for x in dfs_train if isinstance(x[0], pd.DataFrame)]\n",
    "train_dfs_metadata = [x[1] for x in dfs_train if isinstance(x[1], pd.DataFrame)]\n",
    "\n",
    "train_dfs_sentiment  = pd.concat(train_dfs_sentiment, ignore_index=True, sort=False)\n",
    "train_dfs_metadata = pd.concat(train_dfs_metadata, ignore_index=True, sort=False)\n",
    "print(train_dfs_sentiment.shape, train_dfs_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 2438 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 3188 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=6)]: Done 3972 out of 3972 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3865, 6) (14465, 7)\n"
     ]
    }
   ],
   "source": [
    "# Test Set\n",
    "dfs_test = Parallel(n_jobs=6, verbose=1)(delayed(extract_additional_features)(i, mode='test') for i in test_pet_ids)\n",
    "\n",
    "test_dfs_sentiment = [x[0] for x in dfs_test if isinstance(x[0], pd.DataFrame)]\n",
    "test_dfs_metadata = [x[1] for x in dfs_test if isinstance(x[1], pd.DataFrame)]\n",
    "\n",
    "test_dfs_sentiment = pd.concat(test_dfs_sentiment, ignore_index=True, sort=False)\n",
    "test_dfs_metadata = pd.concat(test_dfs_metadata, ignore_index=True, sort=False)\n",
    "print(test_dfs_sentiment.shape, test_dfs_metadata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata_annots_score</th>\n",
       "      <th>metadata_color_score</th>\n",
       "      <th>metadata_color_pixelfrac</th>\n",
       "      <th>metadata_crop_conf</th>\n",
       "      <th>metadata_crop_importance</th>\n",
       "      <th>metadata_annots_top_desc</th>\n",
       "      <th>PetID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973658</td>\n",
       "      <td>0.0748377</td>\n",
       "      <td>0.066331</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>cat black cat</td>\n",
       "      <td>86e1089a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.926158</td>\n",
       "      <td>0.0873303</td>\n",
       "      <td>0.0681004</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>cat whiskers small to medium sized cats</td>\n",
       "      <td>6296e909a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.951545</td>\n",
       "      <td>0.0960851</td>\n",
       "      <td>0.0592612</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>cat small to medium sized cats</td>\n",
       "      <td>6296e909a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.947711</td>\n",
       "      <td>0.0985924</td>\n",
       "      <td>0.0407908</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>dog dog like mammal dog breed</td>\n",
       "      <td>3422e4906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.95744</td>\n",
       "      <td>0.0983332</td>\n",
       "      <td>0.0969476</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>dog dog like mammal dog breed</td>\n",
       "      <td>3422e4906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metadata_annots_score metadata_color_score metadata_color_pixelfrac  \\\n",
       "0              0.973658            0.0748377                 0.066331   \n",
       "1              0.926158            0.0873303                0.0681004   \n",
       "2              0.951545            0.0960851                0.0592612   \n",
       "3              0.947711            0.0985924                0.0407908   \n",
       "4               0.95744            0.0983332                0.0969476   \n",
       "\n",
       "  metadata_crop_conf metadata_crop_importance  \\\n",
       "0                0.8                        1   \n",
       "1                0.8                        1   \n",
       "2                0.8                        1   \n",
       "3                0.8                        1   \n",
       "4                0.8                        1   \n",
       "\n",
       "                  metadata_annots_top_desc      PetID  \n",
       "0                            cat black cat  86e1089a3  \n",
       "1  cat whiskers small to medium sized cats  6296e909a  \n",
       "2           cat small to medium sized cats  6296e909a  \n",
       "3            dog dog like mammal dog breed  3422e4906  \n",
       "4            dog dog like mammal dog breed  3422e4906  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dfs_metadata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend aggregates and imporve column naming\n",
    "aggregates =['mean', 'sum']\n",
    "\n",
    "#Train\n",
    "train_metadata_desc = train_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n",
    "train_metadata_desc = train_metadata_desc.reset_index()\n",
    "train_metadata_desc['metadata_annots_top_desc'] = train_metadata_desc['metadata_annots_top_desc'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "prefix = 'metadata'\n",
    "train_metadata_gr = train_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n",
    "for i in train_metadata_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        train_metadata_gr[i] = train_metadata_gr[i].astype(float)\n",
    "\n",
    "train_metadata_gr = train_metadata_gr.groupby(['PetID']).agg(aggregates)\n",
    "train_metadata_gr.columns = pd.Index([f'{prefix}_{c[0]}_{c[1].upper()}' for c in train_metadata_gr.columns.tolist()])\n",
    "train_metadata_gr = train_metadata_gr.reset_index()\n",
    "\n",
    "train_sentiment_desc = train_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n",
    "train_sentiment_desc = train_sentiment_desc.reset_index()\n",
    "train_sentiment_desc['sentiment_entities']= train_sentiment_desc['sentiment_entities'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "prefix = 'sentiment'\n",
    "train_sentiment_gr = train_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n",
    "for i in train_sentiment_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        train_sentiment_gr[i] = train_sentiment_gr[i].astype(float)\n",
    "\n",
    "train_sentiment_gr = train_sentiment_gr.groupby(['PetID']).agg(aggregates)\n",
    "train_sentiment_gr.columns = pd.Index([f'{prefix}_{c[0]}_{c[1].upper()}' for c in train_sentiment_gr.columns.tolist()])\n",
    "train_sentiment_gr = train_sentiment_gr.reset_index()\n",
    "\n",
    "# Test\n",
    "\n",
    "test_metadata_desc = test_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n",
    "test_metadata_desc = test_metadata_desc.reset_index()\n",
    "test_metadata_desc['metadata_annots_top_desc'] = test_metadata_desc['metadata_annots_top_desc'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "prefix = 'metadata'\n",
    "test_metadata_gr = test_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n",
    "for i in test_metadata_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        test_metadata_gr[i] = test_metadata_gr[i].astype(float)\n",
    "\n",
    "test_metadata_gr = test_metadata_gr.groupby(['PetID']).agg(aggregates)\n",
    "test_metadata_gr.columns = pd.Index([f'{prefix}_{c[0]}_{c[1].upper()}' for c in test_metadata_gr.columns.tolist()])\n",
    "test_metadata_gr = test_metadata_gr.reset_index()\n",
    "\n",
    "test_sentiment_desc = test_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n",
    "test_sentiment_desc = test_sentiment_desc.reset_index()\n",
    "test_sentiment_desc['sentiment_entities']= test_sentiment_desc['sentiment_entities'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "prefix = 'sentiment'\n",
    "test_sentiment_gr = test_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n",
    "for i in test_sentiment_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        test_sentiment_gr[i] = test_sentiment_gr[i].astype(float)\n",
    "\n",
    "test_sentiment_gr = test_sentiment_gr.groupby(['PetID']).agg(aggregates)\n",
    "test_sentiment_gr.columns = pd.Index([f'{prefix}_{c[0]}_{c[1].upper()}' for c in test_sentiment_gr.columns.tolist()])\n",
    "test_sentiment_gr = test_sentiment_gr.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 44) (3972, 43)\n"
     ]
    }
   ],
   "source": [
    "# Train Merges:\n",
    "train_proc = train.copy()\n",
    "train_proc = train_proc.merge(train_sentiment_gr, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(train_metadata_gr, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(train_sentiment_desc, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(train_metadata_desc, how='left', on='PetID')\n",
    "\n",
    "# Test Merges:\n",
    "test_proc = test.copy()\n",
    "test_proc = test_proc.merge(test_sentiment_gr, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(test_metadata_gr, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(test_sentiment_desc, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(test_metadata_desc, how='left', on='PetID')\n",
    "\n",
    "print(train_proc.shape, test_proc.shape)\n",
    "assert train_proc.shape[0] == train.shape[0]\n",
    "assert test_proc.shape[0] == test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breed Mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 48) (3972, 47)\n"
     ]
    }
   ],
   "source": [
    "train_breed_main = train_proc[['Breed1']].merge(\n",
    "                    breed_labels, how='left', left_on='Breed1',\n",
    "                    right_on='BreedID', suffixes=('', '_main_breed'))\n",
    "\n",
    "train_breed_main = train_breed_main.iloc[:,2:]\n",
    "train_breed_main = train_breed_main.add_prefix('main_breed_')\n",
    "\n",
    "train_breed_second = train_proc[['Breed2']].merge(\n",
    "                    breed_labels, how='left', left_on='Breed2',\n",
    "                    right_on='BreedID', suffixes=('', '_second_breed'))\n",
    "\n",
    "train_breed_second = train_breed_second.iloc[:,2:]\n",
    "train_breed_second = train_breed_second.add_prefix('second_breed_')\n",
    "\n",
    "train_proc = pd.concat([train_proc, train_breed_main,train_breed_second], axis=1)\n",
    "\n",
    "test_breed_main = test_proc[['Breed1']].merge(\n",
    "                    breed_labels, how='left',\n",
    "                    left_on='Breed1', right_on='BreedID',\n",
    "                    suffixes=('','_main_breed')\n",
    "                    )\n",
    "\n",
    "test_breed_main = test_breed_main.iloc[:,2:]\n",
    "test_breed_main = test_breed_main.add_prefix('main_breed_')\n",
    "\n",
    "test_breed_second = test_proc[['Breed2']].merge(\n",
    "                    breed_labels, how='left', left_on='Breed2',\n",
    "                    right_on='BreedID', suffixes=('', '_second_breed'))\n",
    "\n",
    "test_breed_second = test_breed_second.iloc[:,2:]\n",
    "test_breed_second = test_breed_second.add_prefix('second_breed_')\n",
    "\n",
    "test_proc = pd.concat([test_proc, test_breed_main,test_breed_second], axis=1)\n",
    "\n",
    "print(train_proc.shape, test_proc.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Train and test\n",
    "### Inspect NaN srtructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN Structure: \n",
      "Type                                               0\n",
      "Name                                            1668\n",
      "Age                                                0\n",
      "Breed1                                             0\n",
      "Breed2                                             0\n",
      "Gender                                             0\n",
      "Color1                                             0\n",
      "Color2                                             0\n",
      "Color3                                             0\n",
      "MaturitySize                                       0\n",
      "FurLength                                          0\n",
      "Vaccinated                                         0\n",
      "Dewormed                                           0\n",
      "Sterilized                                         0\n",
      "Health                                             0\n",
      "Quantity                                           0\n",
      "Fee                                                0\n",
      "State                                              0\n",
      "RescuerID                                          0\n",
      "VideoAmt                                           0\n",
      "Description                                       13\n",
      "PetID                                              0\n",
      "PhotoAmt                                           0\n",
      "AdoptionSpeed                                   3972\n",
      "sentiment_sentiment_magnitude_MEAN               658\n",
      "sentiment_sentiment_magnitude_SUM                658\n",
      "sentiment_sentiment_score_MEAN                   658\n",
      "sentiment_sentiment_score_SUM                    658\n",
      "sentiment_sentiment_document_magnitude_MEAN      658\n",
      "sentiment_sentiment_document_magnitude_SUM       658\n",
      "sentiment_sentiment_document_score_MEAN          658\n",
      "sentiment_sentiment_document_score_SUM           658\n",
      "metadata_metadata_annots_score_MEAN              473\n",
      "metadata_metadata_annots_score_SUM               455\n",
      "metadata_metadata_color_score_MEAN               455\n",
      "metadata_metadata_color_score_SUM                455\n",
      "metadata_metadata_color_pixelfrac_MEAN           455\n",
      "metadata_metadata_color_pixelfrac_SUM            455\n",
      "metadata_metadata_crop_conf_MEAN                 455\n",
      "metadata_metadata_crop_conf_SUM                  455\n",
      "metadata_metadata_crop_importance_MEAN           456\n",
      "metadata_metadata_crop_importance_SUM            455\n",
      "sentiment_entities                               658\n",
      "metadata_annots_top_desc                         455\n",
      "main_breed_Type                                    5\n",
      "main_breed_BreedName                               5\n",
      "second_breed_Type                              13729\n",
      "second_breed_BreedName                         13729\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = pd.concat([train_proc, test_proc], ignore_index=True, sort=False)\n",
    "print(f'NaN Structure: \\n{np.sum(pd.isnull(X))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type            int64\n",
       "Age             int64\n",
       "Breed1          int64\n",
       "Breed2          int64\n",
       "Gender          int64\n",
       "Color1          int64\n",
       "Color2          int64\n",
       "Color3          int64\n",
       "MaturitySize    int64\n",
       "FurLength       int64\n",
       "Vaccinated      int64\n",
       "Dewormed        int64\n",
       "Sterilized      int64\n",
       "Health          int64\n",
       "Quantity        int64\n",
       "Fee             int64\n",
       "State           int64\n",
       "VideoAmt        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_types[column_types == 'int64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tInteger Columns:\n",
      "Type            int64\n",
      "Age             int64\n",
      "Breed1          int64\n",
      "Breed2          int64\n",
      "Gender          int64\n",
      "Color1          int64\n",
      "Color2          int64\n",
      "Color3          int64\n",
      "MaturitySize    int64\n",
      "FurLength       int64\n",
      "Vaccinated      int64\n",
      "Dewormed        int64\n",
      "Sterilized      int64\n",
      "Health          int64\n",
      "Quantity        int64\n",
      "Fee             int64\n",
      "State           int64\n",
      "VideoAmt        int64\n",
      "dtype: object\n",
      "\n",
      "\tFloat Columns:\n",
      "PhotoAmt                                       float64\n",
      "AdoptionSpeed                                  float64\n",
      "sentiment_sentiment_magnitude_MEAN             float64\n",
      "sentiment_sentiment_magnitude_SUM              float64\n",
      "sentiment_sentiment_score_MEAN                 float64\n",
      "sentiment_sentiment_score_SUM                  float64\n",
      "sentiment_sentiment_document_magnitude_MEAN    float64\n",
      "sentiment_sentiment_document_magnitude_SUM     float64\n",
      "sentiment_sentiment_document_score_MEAN        float64\n",
      "sentiment_sentiment_document_score_SUM         float64\n",
      "metadata_metadata_annots_score_MEAN            float64\n",
      "metadata_metadata_annots_score_SUM             float64\n",
      "metadata_metadata_color_score_MEAN             float64\n",
      "metadata_metadata_color_score_SUM              float64\n",
      "metadata_metadata_color_pixelfrac_MEAN         float64\n",
      "metadata_metadata_color_pixelfrac_SUM          float64\n",
      "metadata_metadata_crop_conf_MEAN               float64\n",
      "metadata_metadata_crop_conf_SUM                float64\n",
      "metadata_metadata_crop_importance_MEAN         float64\n",
      "metadata_metadata_crop_importance_SUM          float64\n",
      "main_breed_Type                                float64\n",
      "second_breed_Type                              float64\n",
      "dtype: object\n",
      "\n",
      "\\Categorical Columns:\n",
      "Name                        object\n",
      "RescuerID                   object\n",
      "Description                 object\n",
      "PetID                       object\n",
      "sentiment_entities          object\n",
      "metadata_annots_top_desc    object\n",
      "main_breed_BreedName        object\n",
      "second_breed_BreedName      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "column_types = X.dtypes\n",
    "int_cols = column_types[column_types == 'int64']\n",
    "float_cols = column_types[column_types =='float']\n",
    "cat_cols = column_types[column_types == 'object']\n",
    "\n",
    "print(f'\\tInteger Columns:\\n{int_cols}')\n",
    "print(f'\\n\\tFloat Columns:\\n{float_cols}')\n",
    "print(f'\\n\\Categorical Columns:\\n{cat_cols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = X.copy()\n",
    "\n",
    "text_columns= ['Description','metadata_annots_top_desc','sentiment_entities']\n",
    "categorical_columns=['main_breed_BreedName','second_breed_BreedName']\n",
    "\n",
    "to_drop_columns=['PetID', 'Name','RescuerID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescuer_count = X.groupby(['RescuerID'])['PetID'].count().reset_index()\n",
    "rescuer_count.columns = ['RescuerID','Rescuer_count']\n",
    "\n",
    "# Merger rescuer count\n",
    "X_temp = X_temp.merge(rescuer_count, how='left', on='RescuerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorize categorical columns:\n",
    "for i in categorical_columns:\n",
    "    X_temp.loc[:,i] = pd.factorize(X_temp.loc[:,i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = X_temp[text_columns]\n",
    "\n",
    "for i in X_text.columns:\n",
    "    X_text.loc[:,i] = X_text.loc[:,i].fillna('<MISSING>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Features from: Description\n",
      "Generating Features from: metadata_annots_top_desc\n",
      "Generating Features from: sentiment_entities\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import SparsePCA, TruncatedSVD, LatentDirichletAllocation, NMF\n",
    "\n",
    "n_components = 5\n",
    "text_features=[]\n",
    "\n",
    "# Generate Text Features\n",
    "# Decomposition methods\n",
    "for i in X_text.columns:\n",
    "    print(f'Generating Features from: {i}')\n",
    "    svd_ = TruncatedSVD(n_components=n_components, random_state=221)\n",
    "    nmf_ = NMF(n_components=n_components, random_state=221)\n",
    "    \n",
    "    tfidf_col = TfidfVectorizer().fit_transform(X_text.loc[:,i].values)\n",
    "    svd_col = svd_.fit_transform(tfidf_col)\n",
    "    svd_col = pd.DataFrame(svd_col)\n",
    "    svd_col = svd_col.add_prefix(f'SVD_{i}_')\n",
    "    \n",
    "    nmf_col = nmf_.fit_transform(tfidf_col)\n",
    "    nmf_col = pd.DataFrame(nmf_col)\n",
    "    nmf_col = nmf_col.add_prefix(f'NMF_{i}_')\n",
    "    \n",
    "    text_features.append(svd_col)\n",
    "    text_features.append(nmf_col)\n",
    "    \n",
    "# Combine extracted features:\n",
    "text_features = pd.concat(text_features, axis =1)\n",
    "\n",
    "# Concatenate with main df:\n",
    "X_temp = pd.concat([X_temp,text_features], axis=1)\n",
    "\n",
    "# Remove raw text columns\n",
    "for i in X_text.columns:\n",
    "    X_temp = X_temp.drop(i, axis =1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (18965, 73)\n"
     ]
    }
   ],
   "source": [
    "# Remove unnecessary columns:\n",
    "X_temp = X_temp.drop(to_drop_columns, axis=1)\n",
    "\n",
    "# Check final df shape:\n",
    "print(f'X shape: {X_temp.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (14993, 73)\n",
      "X_test shape: (3972, 72)\n"
     ]
    }
   ],
   "source": [
    "# Split training and test set\n",
    "X_train = X_temp.loc[np.isfinite(X_temp['AdoptionSpeed']),:]\n",
    "X_test = X_temp.loc[~np.isfinite(X_temp['AdoptionSpeed']),:]\n",
    "\n",
    "# Remove missing target column from test:\n",
    "X_test = X_test.drop(['AdoptionSpeed'], axis=1)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "      \n",
    "assert X_train.shape[0] ==  train.shape[0]\n",
    "assert X_test.shape[0] == test.shape[0]\n",
    "      \n",
    "# Check if columns between the two DFs are the same\n",
    "train_cols = X_train.columns.tolist()\n",
    "train_cols.remove('AdoptionSpeed')\n",
    "      \n",
    "test_cols = X_test.columns.tolist()\n",
    "      \n",
    "assert np.all(train_cols == test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type                                             0\n",
       "Age                                              0\n",
       "Breed1                                           0\n",
       "Breed2                                           0\n",
       "Gender                                           0\n",
       "Color1                                           0\n",
       "Color2                                           0\n",
       "Color3                                           0\n",
       "MaturitySize                                     0\n",
       "FurLength                                        0\n",
       "Vaccinated                                       0\n",
       "Dewormed                                         0\n",
       "Sterilized                                       0\n",
       "Health                                           0\n",
       "Quantity                                         0\n",
       "Fee                                              0\n",
       "State                                            0\n",
       "VideoAmt                                         0\n",
       "PhotoAmt                                         0\n",
       "AdoptionSpeed                                    0\n",
       "sentiment_sentiment_magnitude_MEAN             551\n",
       "sentiment_sentiment_magnitude_SUM              551\n",
       "sentiment_sentiment_score_MEAN                 551\n",
       "sentiment_sentiment_score_SUM                  551\n",
       "sentiment_sentiment_document_magnitude_MEAN    551\n",
       "sentiment_sentiment_document_magnitude_SUM     551\n",
       "sentiment_sentiment_document_score_MEAN        551\n",
       "sentiment_sentiment_document_score_SUM         551\n",
       "metadata_metadata_annots_score_MEAN            356\n",
       "metadata_metadata_annots_score_SUM             341\n",
       "                                              ... \n",
       "SVD_Description_0                                0\n",
       "SVD_Description_1                                0\n",
       "SVD_Description_2                                0\n",
       "SVD_Description_3                                0\n",
       "SVD_Description_4                                0\n",
       "NMF_Description_0                                0\n",
       "NMF_Description_1                                0\n",
       "NMF_Description_2                                0\n",
       "NMF_Description_3                                0\n",
       "NMF_Description_4                                0\n",
       "SVD_metadata_annots_top_desc_0                   0\n",
       "SVD_metadata_annots_top_desc_1                   0\n",
       "SVD_metadata_annots_top_desc_2                   0\n",
       "SVD_metadata_annots_top_desc_3                   0\n",
       "SVD_metadata_annots_top_desc_4                   0\n",
       "NMF_metadata_annots_top_desc_0                   0\n",
       "NMF_metadata_annots_top_desc_1                   0\n",
       "NMF_metadata_annots_top_desc_2                   0\n",
       "NMF_metadata_annots_top_desc_3                   0\n",
       "NMF_metadata_annots_top_desc_4                   0\n",
       "SVD_sentiment_entities_0                         0\n",
       "SVD_sentiment_entities_1                         0\n",
       "SVD_sentiment_entities_2                         0\n",
       "SVD_sentiment_entities_3                         0\n",
       "SVD_sentiment_entities_4                         0\n",
       "NMF_sentiment_entities_0                         0\n",
       "NMF_sentiment_entities_1                         0\n",
       "NMF_sentiment_entities_2                         0\n",
       "NMF_sentiment_entities_3                         0\n",
       "NMF_sentiment_entities_4                         0\n",
       "Length: 73, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pd.isnull(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type                                             0\n",
       "Age                                              0\n",
       "Breed1                                           0\n",
       "Breed2                                           0\n",
       "Gender                                           0\n",
       "Color1                                           0\n",
       "Color2                                           0\n",
       "Color3                                           0\n",
       "MaturitySize                                     0\n",
       "FurLength                                        0\n",
       "Vaccinated                                       0\n",
       "Dewormed                                         0\n",
       "Sterilized                                       0\n",
       "Health                                           0\n",
       "Quantity                                         0\n",
       "Fee                                              0\n",
       "State                                            0\n",
       "VideoAmt                                         0\n",
       "PhotoAmt                                         0\n",
       "sentiment_sentiment_magnitude_MEAN             107\n",
       "sentiment_sentiment_magnitude_SUM              107\n",
       "sentiment_sentiment_score_MEAN                 107\n",
       "sentiment_sentiment_score_SUM                  107\n",
       "sentiment_sentiment_document_magnitude_MEAN    107\n",
       "sentiment_sentiment_document_magnitude_SUM     107\n",
       "sentiment_sentiment_document_score_MEAN        107\n",
       "sentiment_sentiment_document_score_SUM         107\n",
       "metadata_metadata_annots_score_MEAN            117\n",
       "metadata_metadata_annots_score_SUM             114\n",
       "metadata_metadata_color_score_MEAN             114\n",
       "                                              ... \n",
       "SVD_Description_0                                0\n",
       "SVD_Description_1                                0\n",
       "SVD_Description_2                                0\n",
       "SVD_Description_3                                0\n",
       "SVD_Description_4                                0\n",
       "NMF_Description_0                                0\n",
       "NMF_Description_1                                0\n",
       "NMF_Description_2                                0\n",
       "NMF_Description_3                                0\n",
       "NMF_Description_4                                0\n",
       "SVD_metadata_annots_top_desc_0                   0\n",
       "SVD_metadata_annots_top_desc_1                   0\n",
       "SVD_metadata_annots_top_desc_2                   0\n",
       "SVD_metadata_annots_top_desc_3                   0\n",
       "SVD_metadata_annots_top_desc_4                   0\n",
       "NMF_metadata_annots_top_desc_0                   0\n",
       "NMF_metadata_annots_top_desc_1                   0\n",
       "NMF_metadata_annots_top_desc_2                   0\n",
       "NMF_metadata_annots_top_desc_3                   0\n",
       "NMF_metadata_annots_top_desc_4                   0\n",
       "SVD_sentiment_entities_0                         0\n",
       "SVD_sentiment_entities_1                         0\n",
       "SVD_sentiment_entities_2                         0\n",
       "SVD_sentiment_entities_3                         0\n",
       "SVD_sentiment_entities_4                         0\n",
       "NMF_sentiment_entities_0                         0\n",
       "NMF_sentiment_entities_1                         0\n",
       "NMF_sentiment_entities_2                         0\n",
       "NMF_sentiment_entities_3                         0\n",
       "NMF_sentiment_entities_4                         0\n",
       "Length: 72, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pd.isnull(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "\n",
    "# The following 3 functions have been taken from Ben Hamner's github repository\n",
    "# https://github.com/benhamner/Metrics\n",
    "\n",
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    \n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)] for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating = None\n",
    "    max_rating = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
